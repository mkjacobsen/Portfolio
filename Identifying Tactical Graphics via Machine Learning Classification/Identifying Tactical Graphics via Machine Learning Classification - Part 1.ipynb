{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying Tactical Graphics via Machine Learning Classification - Part 1\n",
    "## By: Matthew Jacobsen, updated: 5/4/2020\n",
    "\n",
    "In one of my other [articles](), I went through the process needed to video screen record a user terminal for use the both quantitative and qualitative assessment of systems. Near the end of that tutorial, I demonstrated how to take the information on a map based screen image and convert it to tabular data for statistical analysis.  \n",
    "\n",
    "One aspect that we did not cover in that project was how to enhance the information devliered for evaluation.  In particular, the data obtained from the previous process included time stamps for new graphics appearing and the real world coordinates.  However, we could not inform the evaluator of the *type* of graphic being observed.  In this walkthrough, we will cover how to isolate and extract additional graphics from frames as they appear.  In addition, we will go over the use of machine learning techniques to identify and textualize what graphic the computer believes was observed.  \n",
    "\n",
    "### Why?\n",
    "\n",
    "For those unfamiliar with the process of system evaluation or testing, this may seem like a significant amount of work for only a modest gain in information. In some sense, this is true. However, the goal of operational testing is to ensure a quality system is delivered to the end user and that it is reliable in the information it delivers.  In order to achieve such an assessment, we need to be able to evaluate, as in the previous article, position accuracy and delivery timeliness, but also the accuracy of the information itself. \n",
    "\n",
    "In order to get a concept of how large a problem space this is, take a look at the [quantity of graphics that can be displayed to a Soldier](www.spatialillusions.com/unitgenerator).  This mind-bogglingly large quantity of graphics, along with the fact that evaluators seldom have reason to understand all of them, can quickly convince you that this problem is either (1) too difficult or (2) not worth the effort. However, there are a multitude of walkthroughs on the internet showing how to construct a classifier for distinguishing dogs and cats, so the idea is reasonable.  \n",
    "\n",
    "This is exactly the reason that we turn to machine learning methods for image classification.  This problem is beyond the scope of any individual evaluator and, as would be expected, the Mark 1 eyeball is not an appropriate tool for this task (yay, military evaluator humor). We just need to make it work for a *substantially larger set* of graphics and we would want an automated pathway, so we can reduce the burden on the analyst/evaluator.\n",
    "\n",
    "The immediate benefit is that, if we can build such a classifier, we can automate the process so the evaluator gets results that indicate how accurate the graphical position was to the data that was received or sent, how timely that data was (how long it took to get to the out port of the computer), *and* how accurate the graphic was to what was intended. Given these are the three critical elements of any information on a command and control system, this is enough to say whether said system meets its intended purpose from a functional standpoint. Anything beyond that is how useful the system is to the actual user, which is a separate evaluation construct altogether.\n",
    "\n",
    "### The Process\n",
    "\n",
    "While we could follow walkthroughs that already exist for similar problems, this problem is unique enough, that it merits going through the process required.  So, here are our steps:\n",
    "\n",
    "- First, we need to obtain *as complete as possible* a set of military graphics for use. \n",
    "\n",
    "- Next, we need to create a set of graphics overlaid on various maps. The reason for this is that we want our machine learning algorithm to focus on the graphic and features of it, as opposed to the background.  So, we can help out a bit by providing as broad and random as possible a set of backgrounds, to discourage such a focus. This process should generate both a training/test set and a validation set, so we have some measure of how our algorithm will perform in the real world.\n",
    "\n",
    "- Finally, we will need to train and test the algorithm, as well as package it for use outside of our development environment.\n",
    "\n",
    "We also have some requirements of the process.  For example, the huge quantity of graphics available will necessitate an automated process. This is not just to save us some work now, but also for the future, as these graphics are updated on a fairly routine basis (exactly why is a question better left for others than me). \n",
    "\n",
    "With all that said, let's dive in.  This part of the full walkthrough will focus on the first two parts of our process. We will cover how to automatically obtain the graphics and how to merge them with backgrounds in an automatic fashion to obtain our graphical data. There are other methods we can use later to extend our graphics base set, so that our algorithm can be less dependent on orientation, but for now we'll stick to simpler methods of accomplishing this.\n",
    "\n",
    "### Obtaining the Graphics\n",
    "\n",
    "As linked earlier, the nice folks at Spatial Illusions have created a web-based Javascript application to build a wide range of military graphics. Figure 1 below shows a screen capture of this website. Since we are looking for an automatic method of generating the graphics, we can make use of this website to simplify our process and push the collection of graphics to Python. \n",
    "\n",
    "<img src='spatialillusions.png'>\n",
    "<b><center>Figure 1 : Spatial Illusion's Unit Generator</center></b>\n",
    "\n",
    "In order to do this, you will need the Selenium package, which allows Python (and other code bases) to interact with websites in an automatic fashion.  Figure 1 also includes several dropdown menus boxed in red.  These are the main elements that we will be iterating through the collect our graphics.  \n",
    "\n",
    "First, let's import the packages we need, which also includes the BeautifulSoup package for extracting and parsing web elements.  We'll also define our website name, to save time later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.webdriver.support.ui import Select, WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pickle\n",
    "import re\n",
    "import os\n",
    "\n",
    "url1 = 'https://spatialillusions.com/unitgenerator/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a set of functions to help out later.  The first will instantiate our webdriver for Selenium and the second will collect the current options in any of the dropdown menus.  This will be important as those options will update as the code cycles through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument('--incognito')\n",
    "\n",
    "    browser = webdriver.Chrome(r'C:\\Users\\Matt\\Documents\\Personal File\\Python Code Packages\\selenium_drivers\\chromedriver.exe', options=options)\n",
    "    \n",
    "    return browser\n",
    "\n",
    "def update_options(handle, driver):\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    updated_options = [\n",
    "        [\n",
    "            x for x in b.find_all('li')\n",
    "        ] for b in soup.find_all('div',{'class':handle})\n",
    "    ]\n",
    "    updated_options = [x.text for x in updated_options[0]]\n",
    "\n",
    "    return updated_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need to consider how to store our graphics.  The graphics generated by this website are encoded as base64 text strings, so we are using a data dictionary that will have a numerical key (incremented by the graphic number).  Inside this will be three sub-elements, the text description of the graphic, the symbol code (which is a character string representing that graphic), and the base64 test itself, which we can convert to a graphic later.\n",
    "\n",
    "Just in case there is a problem, we don't want to start over from square one, so we'll have the code check to see if there are already stored graphics to use, and make sure it starts from that point.  If not, then it will start from the beginning.  NOTE: Make sure that this code is in the executable portion of your final package, otherwise you'll end up starting from scratch after the first attempt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_graphics = {}\n",
    "\n",
    "for file in os.listdir():\n",
    "    if file == 'collected_graphics.pkl':\n",
    "        with open('collected_graphics.pkl','rb') as infile:\n",
    "            collected_graphics = pickle.load(infile)\n",
    "            \n",
    "            starting_elements = collected_graphics[list(collected_graphics.keys())[len(collected_graphics.keys())-1]]['symbol_text'].split('|')\n",
    "            \n",
    "            cs_start = starting_elements[0]\n",
    "            aff_start = starting_elements[1]\n",
    "            bd_start = starting_elements[2]\n",
    "            stat_start = starting_elements[3]\n",
    "            fid_start = starting_elements[4]\n",
    "            \n",
    "            counter = list(collected_graphics.keys())[len(collected_graphics.keys())-1]\n",
    "            \n",
    "            aff_flag = True\n",
    "            bd_flag = True\n",
    "            stat_flag = True\n",
    "            fid_flag = True\n",
    "\n",
    "if collected_graphics == {}:\n",
    "    cs_start = None\n",
    "    aff_start = None\n",
    "    bd_start = None\n",
    "    stat_start = None\n",
    "    fid_start = None\n",
    "    counter = 0   \n",
    "\n",
    "    aff_flag = False\n",
    "    bd_flag = False\n",
    "    stat_flag = False\n",
    "    fid_flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's limit the graphics we look at a bit, to streamline the process. To demonstrate that the graphics are **are not capturing** won't matter very much, you can take a look and compare the differences. Although you could try to interact with all elements by class name or some other variable, **lots** of experimentatation was done to find the combination that worked the best.  By using absolute xpaths, we leave ourselves vulnerable if the website structure changes, but this is likely to be relatively easy to fix. \n",
    "\n",
    "After defining our elements, we start by selecting values from each of the dropdowns and interating through them. The scheme through which we have done this puts the two smallest lists at the bottom.  This is especially important, as interacting with the Function ID menu was found to be finnicky, so going through that just one time proved to be the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = web_driver()\n",
    "driver.get(url1)\n",
    "driver.implicitly_wait(30)\n",
    "\n",
    "affiliation_list = ['Pending','Unknown','Assumed Friend','Friend','Neutral','Suspect','Hostile']\n",
    "status_list = ['Anticipated/Planned','Present']\n",
    "\n",
    "\n",
    "cs_text_xpath = '/html/body/section/div/div[1]/div[3]/div/div[2]/ul/li[{}]'\n",
    "aff_text_xpath = '/html/body/section/div/div[1]/div[4]/div/div[2]/ul/li[{}]'\n",
    "bd_text_xpath = '/html/body/section/div/div[1]/div[5]/div/div[2]/ul/li[{}]'\n",
    "stat_text_xpath = '/html/body/section/div/div[1]/div[6]/div/div[2]/ul/li[{}]'\n",
    "fid_text_xpath = '/html/body/section/div/div[1]/div[7]/div/div[2]/ul/li[{}]'\n",
    "\n",
    "cs_curopt_xpath = \"/html/body/section/div/div[1]/div[3]/div/div[1]/*[@class='mdc-select__selected-text']\"\n",
    "aff_curopt_xpath = \"/html/body/section/div/div[1]/div[4]/div/div[1]/*[@class='mdc-select__selected-text']\"\n",
    "bd_curopt_xpath = \"/html/body/section/div/div[1]/div[5]/div/div[1]/*[@class='mdc-select__selected-text']\"\n",
    "stat_curopt_xpath = \"/html/body/section/div/div[1]/div[6]/div/div[1]/*[@class='mdc-select__selected-text']\"\n",
    "fid_curopt_xpath = \"/html/body/section/div/div[1]/div[7]/div/div[1]/*[@class='mdc-select__selected-text']\"\n",
    "\n",
    "cs_menu = driver.find_element_by_class_name(\"coding-scheme\")\n",
    "aff_menu = driver.find_element_by_class_name(\"affiliation\")\n",
    "bd_menu = driver.find_element_by_class_name(\"battle-dimension\")\n",
    "stat_menu = driver.find_element_by_class_name(\"status\")\n",
    "fid_menu = driver.find_element_by_class_name(\"function-id\")\n",
    "\n",
    "cs_curopt = driver.find_element_by_xpath(cs_curopt_xpath)\n",
    "aff_curopt = driver.find_element_by_xpath(aff_curopt_xpath)\n",
    "bd_curopt = driver.find_element_by_xpath(bd_curopt_xpath)\n",
    "stat_curopt = driver.find_element_by_xpath(stat_curopt_xpath)\n",
    "fid_curopt = driver.find_element_by_xpath(fid_curopt_xpath)\n",
    "\n",
    "cs_options = update_options(\"coding-scheme\", driver)\n",
    "\n",
    "if cs_start != None:\n",
    "    cs_index = cs_options.index(cs_start)\n",
    "else:\n",
    "    cs_index = 0\n",
    "    \n",
    "while cs_index <= len(cs_options)-1:\n",
    "    cs_ext = cs_options[cs_index]\n",
    "    \n",
    "    print(cs_ext)\n",
    "    cs_actions = ActionChains(driver)\n",
    "        \n",
    "    cs_selector = driver.find_element_by_xpath(cs_text_xpath.format(cs_index+1))\n",
    "    cs_actions.move_to_element(cs_menu).pause(2).perform()\n",
    "    cs_actions.click().pause(2).perform()\n",
    "    cs_actions = ActionChains(driver)\n",
    "\n",
    "    cs_actions.move_to_element(cs_selector).pause(2).perform()\n",
    "    cs_actions.click().pause(2).perform()\n",
    "    \n",
    "    bd_options = update_options(\"battle-dimension\", driver)\n",
    "    \n",
    "    if (bd_start != None) and (bd_flag):\n",
    "        bd_index = bd_options.index(bd_start)\n",
    "        bd_flag = False\n",
    "\n",
    "    else:\n",
    "        bd_index = 0   \n",
    "\n",
    "    while bd_index <= len(bd_options)-1:\n",
    "        bd_ext = bd_options[bd_index]\n",
    "\n",
    "        print('-'+bd_ext)\n",
    "        bd_actions = ActionChains(driver)\n",
    "\n",
    "        bd_selector = driver.find_element_by_xpath(bd_text_xpath.format(bd_index+1))\n",
    "        bd_actions.move_to_element(bd_menu).pause(2).perform()\n",
    "        bd_actions.click().pause(2).perform()\n",
    "        bd_actions = ActionChains(driver)\n",
    "\n",
    "        bd_actions.move_to_element(bd_selector).pause(2).perform()\n",
    "        bd_actions.click().pause(2).perform()\n",
    "        \n",
    "        fid_options = update_options(\"function-id\", driver)\n",
    "        fid_options = [re.sub(r'[^0-9A-Za-z-_ ]+',' ',x) for x in fid_options]\n",
    "        if (fid_start != None) and (fid_flag):\n",
    "            fid_index = fid_options.index(fid_start)\n",
    "            fid_flag = False\n",
    "        else:\n",
    "            fid_index = 0\n",
    "        \n",
    "        while fid_index <= len(fid_options)-1:\n",
    "            fid_ext = fid_options[fid_index]\n",
    "\n",
    "            print('--'+fid_ext)\n",
    "            \n",
    "            while re.sub(r'[^0-9A-Za-z-_ ]+',' ',fid_curopt.text).strip() != re.sub(r'[^0-9A-Za-z-_ ]+',' ',fid_ext).strip():\n",
    "                fid_actions = ActionChains(driver)\n",
    "\n",
    "                fid_selector = driver.find_element_by_xpath(fid_text_xpath.format(fid_index+1))\n",
    "                fid_actions.move_to_element(fid_menu).pause(2).perform()\n",
    "                fid_actions.click().pause(2).perform()\n",
    "                fid_actions = ActionChains(driver)\n",
    "\n",
    "                fid_actions.move_to_element(fid_selector).pause(2).perform()\n",
    "                fid_actions.click().pause(2).perform()\n",
    "            \n",
    "            stat_options = update_options(\"status\", driver)\n",
    "            \n",
    "            if (stat_start != None) and (stat_flag):\n",
    "                stat_index = stat_options.index(stat_start)\n",
    "                stat_flag = False\n",
    "\n",
    "            else:\n",
    "                stat_index = 0\n",
    "                stat_actions = ActionChains(driver)\n",
    "                stat_selector = driver.find_element_by_xpath(stat_text_xpath.format(stat_index+1))\n",
    "                stat_actions.move_to_element(stat_menu).pause(2).perform()\n",
    "                stat_actions.click().pause(2).perform()\n",
    "                stat_actions = ActionChains(driver)\n",
    "\n",
    "                stat_actions.move_to_element(stat_selector).pause(2).perform()\n",
    "                stat_actions.click().pause(2).perform()\n",
    "                                    \n",
    "            while stat_index <= len(status_list)-1:\n",
    "                stat_ext = status_list[stat_index]\n",
    "\n",
    "                print('---'+stat_ext)\n",
    "                while stat_curopt.text != stat_ext:\n",
    "                    stat_actions = ActionChains(driver)\n",
    "\n",
    "                    stat_actions.move_to_element(stat_menu).pause(2).perform()\n",
    "                    stat_actions.click().pause(2).perform()\n",
    "                    stat_actions = ActionChains(driver)\n",
    "                    stat_actions.send_keys(Keys.DOWN).pause(2).perform()\n",
    "                    stat_actions = ActionChains(driver)\n",
    "                    stat_actions.send_keys(Keys.ENTER).pause(2).perform()\n",
    "                \n",
    "                aff_options = update_options(\"affiliation\", driver)\n",
    "    \n",
    "                if (aff_start != None) and (aff_flag) and (stat_flag) :\n",
    "                    aff_index = aff_options.index(aff_start)\n",
    "                    aff_flag = False\n",
    "\n",
    "                else:\n",
    "                    aff_index = 0\n",
    "                    aff_actions = ActionChains(driver)\n",
    "                    aff_selector = driver.find_element_by_xpath(aff_text_xpath.format(aff_index+1))\n",
    "                    aff_actions.move_to_element(aff_menu).pause(2).perform()\n",
    "                    aff_actions.click().pause(2).perform()\n",
    "                    aff_actions = ActionChains(driver)\n",
    "\n",
    "                    aff_actions.move_to_element(aff_selector).pause(2).perform()\n",
    "                    aff_actions.click().pause(2).perform()\n",
    "                \n",
    "                while aff_index <= len(affiliation_list)-1:\n",
    "                    aff_ext = affiliation_list[aff_index]\n",
    "\n",
    "                    print('----'+aff_ext)\n",
    "                    while aff_curopt.text != aff_ext:\n",
    "                        aff_actions = ActionChains(driver)\n",
    "\n",
    "                        aff_actions.move_to_element(aff_menu).pause(2).perform()\n",
    "                        aff_actions.click().pause(2).perform()\n",
    "                        aff_actions = ActionChains(driver)\n",
    "                        aff_actions.send_keys(Keys.DOWN).pause(2).perform()\n",
    "                        aff_actions = ActionChains(driver)\n",
    "                        aff_actions.send_keys(Keys.ENTER).pause(2).perform()\n",
    "                    \n",
    "                    symbol_information = driver.find_element_by_class_name(\"svg-symbol\")\n",
    "                    image_information = driver.find_element_by_xpath('/html/body/section/div/div[1]/div[1]/center/div/img')\n",
    "                    \n",
    "                    collected_graphics[counter] = {}\n",
    "                    collected_graphics[counter]['symbol_text'] = cs_ext+'|'+aff_ext+'|'+bd_ext+'|'+stat_ext+'|'+fid_ext\n",
    "                    collected_graphics[counter]['symbol_code'] = symbol_information.get_attribute('sidc')\n",
    "                    collected_graphics[counter]['base64_img_src'] = image_information.get_attribute('src')\n",
    "                    \n",
    "                    aff_index += 1\n",
    "                    counter += 1   \n",
    "                \n",
    "                stat_index += 1\n",
    "            \n",
    "            fid_index += 1\n",
    "        \n",
    "        bd_index += 1\n",
    "    \n",
    "    cs_index += 1\n",
    "\n",
    "driver.close()\n",
    "\n",
    "with open('collected_graphics.pkl','wb') as outfile:\n",
    "    pickle.dump(collected_graphics, outfile, protocol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part **will** take a while.  During my initial collection of these graphics, it took over a week of constant running to aggregate a set of graphics that I was happy with, so be prepared to spend some time on this.  \n",
    "\n",
    "### Converting Graphics \n",
    "\n",
    "Now that we have our graphics, we will have to convert them into actual images from the base64 text they are generated as.  Lucky for us, this is a fairly simple process.  In order to convert them, we will use the python imaging library (PIL), the base64 library, and the io library.  The process is shown below. In order to demonstrate this, we have an example base64 string image below and are using the matplotlib library to show the graphic inline. \n",
    "\n",
    "In this example, we take the base64 text and decode it, then use the IO library to pipe that output into PIL's image stream.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19234109a08>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD6CAYAAACf653dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAPcklEQVR4nO3dcayddX3H8fdnLYhTl14UsFAy0DQKWUZxdx2GZdEqpmNOMXGJaEz/IClLNMHMTKlLNk0002SK+2Mh1IE0xgkOdSBhalMhxmQpXqRA6xWLiLO2oxoPUfcHWeG7P87T5a67Xc+955z76zn3/UpOzvP8zu+c5/tLTz88/M7z9JeqQpK08n6jdQGStFoZwJLUiAEsSY0YwJLUiAEsSY0YwJLUyFABnGRrkseTPJHkxlEVJUmrQZZ7HXCSNcAPgKuAQ8B3gGur6nsne8+6devq/PPPX9bxJGlSzc/P/7yqzjmxfe0Qn7kZeKKqngRIcgfwVuCkAXz++efzuc99bohDStLkmZ2d/fFi7cNMQVwA/GTB/qGuTZI0gGECOIu0/Z/5jCTbk8wlmev1ekMcTpKmyzABfAi4cMH+BuDwiZ2qamdVzVbV7MzMzBCHk6TpMswc8HeAjUkuBn4KvAN451I/ZHZ2dogSJOn0cssttwzcd9kBXFXHkrwX+DqwBritqg4s9/MkabUZ5gyYqroPuG9EtUjSquKdcJLUiAEsSY0MNQUxLn/6t4NPYktSK1/dcf1Q7/cMWJIaMYAlqREDWJIaMYAlqZHT8ke4xfzetdtblyBpFTvy2EMj/0zPgCWpEQNYkhoxgCWpEQNYkhoxgCWpEQNYkhoxgCWpEQNYkhoZ6kaMJE8BvwKeA45VlesLSdKARnEn3Our6ucj+BxJWlWcgpCkRoYN4AK+keShJP5jDZK0BMNOQVxZVYeTnAvsTvL9qvrWwg5dMG8HePnLXz7k4SRpegx1BlxVh7vno8BXgM2L9NlZVbNVNTszMzPM4SRpqiw7gJO8KMlLjm8DbwL2j6owSZp2w0xBnAd8Jcnxz/mnqvraSKqSpFVg2QFcVU8Cl42wFklaVbwMTZIaMYAlqREDWJIaMYAlqREDWJIaMYAlqREDWJIaMYAlqREDWJIaMYAlqREDWJIaMYAlqREDWJIaMYAlqREDWJIaMYAlqREDWJIaOWUAJ7ktydEk+xe0nZ1kd5KD3bOrbUrSEg1yBnw7sPWEthuBPVW1EdjT7UuSluCUAVxV3wJ+cULzW4Fd3fYu4JoR1yVJU2+5c8DnVdURgO753JN1TLI9yVySuV6vt8zDSdL0GfuPcFW1s6pmq2p2ZsapYkk6brkB/HSS9QDd89HRlSRJq8NyA/geYFu3vQ24ezTlSNLqMchlaF8A/g14VZJDSa4DPg5cleQgcFW3L0lagrWn6lBV157kpTeMuBZJWlW8E06SGjGAJakRA1iSGjGAJakRA1iSGjGAJakRA1iSGjGAJakRA1iSGjGAJakRA1iSGjGAJakRA1iSGjGAJakRA1iSGjGAJamRQVbEuC3J0ST7F7R9OMlPk+zrHlePt0xJmj6DnAHfDmxdpP2mqtrUPe4bbVmSNP1OGcBV9S3gFytQiyStKsPMAb83yaPdFMXMyCqSpFViuQF8M/BKYBNwBPjkyTom2Z5kLslcr9db5uEkafosK4Cr6umqeq6qngc+A2z+f/rurKrZqpqdmfFEWZKOW1YAJ1m/YPdtwP6T9ZUkLW7tqTok+QLwOuBlSQ4BfwO8LskmoICngOvHWKMkTaVTBnBVXbtI861jqEWSVhXvhJOkRgxgSWrEAJakRgxgSWrEAJakRgxgSWrEAJakRgxgSWrEAJakRgxgSWrEAJakRgxgSWrEAJakRgxgSWrEAJakRgxgSWrklAGc5MIk9yeZT3IgyQ1d+9lJdic52D274JskLcEgZ8DHgPdX1SXAFcB7klwK3AjsqaqNwJ5uX5I0oFMGcFUdqarvdtu/AuaBC4C3Aru6bruAa8ZVpCRNoyXNASe5CLgc2AucV1VHoB/SwLmjLk6SptnAAZzkxcCXgPdV1S+X8L7tSeaSzPV6veXUKElTaaAATnIG/fD9fFV9uWt+Osn67vX1wNHF3ltVO6tqtqpmZ2b8nU6SjhvkKojQX4Z+vqo+teCle4Bt3fY24O7RlydJ02vtAH2uBN4NPJZkX9f2IeDjwBeTXAf8O/Bn4ylRkqbTKQO4qr4N5CQvv2G05UjS6uGdcJLUiAEsSY0YwJLUiAEsSY0YwJLUiAEsSY0YwJLUiAEsSY0YwJLUiAEsSY0YwJLUiAEsSY0YwJLUiAEsSY0YwJLUiAEsSY0YwJLUyCBrwl2Y5P4k80kOJLmha/9wkp8m2dc9rh5/uZI0PQZZE+4Y8P6q+m6SlwAPJdndvXZTVf3d+MqTpOk1yJpwR4Aj3favkswDF4y7MEmadkuaA05yEXA5sLdrem+SR5PclmTmJO/ZnmQuyVyv1xuqWEmaJgMHcJIXA18C3ldVvwRuBl4JbKJ/hvzJxd5XVTuraraqZmdmFs1oSVqVBgrgJGfQD9/PV9WXAarq6ap6rqqeBz4DbB5fmZI0fQa5CiLArcB8VX1qQfv6Bd3eBuwffXmSNL0GuQriSuDdwGNJ9nVtHwKuTbIJKOAp4PqxVChJU2qQqyC+DWSRl+4bfTmStHp4J5wkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjBrAkNWIAS1IjgyxJdFaSB5M8kuRAko907Rcn2ZvkYJI7k5w5/nIlaXoMcgb8LLClqi6jvwLy1iRXAJ8AbqqqjUAPuG58ZUrS9DllAFffr7vdM7pHAVuAu7r2XcA1Y6lQkqbUoMvSr+kW5DwK7AZ+CDxTVce6LoeAC8ZToiRNp4ECuKqeq6pNwAZgM3DJYt0We2+S7Unmksz1er3lVypJU2ZJV0FU1TPAA8AVwLokx1dV3gAcPsl7dlbVbFXNzszMDFOrJE2VQa6COCfJum77hcAbgXngfuDtXbdtwN3jKlKSptHaU3dhPbAryRr6gf3Fqro3yfeAO5J8FHgYuHWMdUrS1DllAFfVo8Dli7Q/SX8+WJK0DN4JJ0mNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1IgBLEmNGMCS1MggSxKdleTBJI8kOZDkI1377Ul+lGRf99g0/nIlaXoMsiTRs8CWqvp1kjOAbyf51+61v6yqu8ZXniRNr0GWJCrg193uGd1j0SXoJUmDG2gOOMmaJPuAo8DuqtrbvfSxJI8muSnJC8ZWpSRNoYECuKqeq6pNwAZgc5LfAXYArwZ+Hzgb+OBi702yPclckrlerzeisiVp8i3pKoiqegZ4ANhaVUeq71ngs5xkheSq2llVs1U1OzMzM3TBkjQtBrkK4pwk67rtFwJvBL6fZH3XFuAaYP84C5WkaTPIVRDrgV1J1tAP7C9W1b1JvpnkHCDAPuDPx1inJE2dQa6CeBS4fJH2LWOpSJJWCe+Ek6RGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJasQAlqRGDGBJamTgAO5WRn44yb3d/sVJ9iY5mOTOJGeOr0xJmj5LOQO+AZhfsP8J4Kaq2gj0gOtGWZgkTbtB1oQjyQbgT4CPAX/RLcS5BXhn12UX8GHg5jHUCMCRxx4a10dLUhODngF/GvgA8Hy3/1Lgmao61u0fAi4YcW2SNNUGWZb+zcDRqlp4CppFutZJ3r89yVySuV6vt8wyJWn6DDIFcSXwliRXA2cBv0X/jHhdkrXdWfAG4PBib66qncBOgEsvvXTRkJak1eiUZ8BVtaOqNlTVRcA7gG9W1buA+4G3d922AXePrUpJmkID/Qh3Eh8E7kjyUeBh4NbRlARf3XH9qD5Kkk5bSwrgqnoAeKDbfhLYPPqSJGl18E44SWrEAJakRgxgSWpkmB/hRuKWW25pXYIkNeEZsCQ1YgBLUiMGsCQ1YgBLUiOpWrl/niHJz4AfAy8Dfr5iBx4vx3L6mZZxwPSMZVrGAcsby29X1TknNq5oAP/PQZO5qppd8QOPgWM5/UzLOGB6xjIt44DRjsUpCElqxACWpEZaBfDORscdB8dy+pmWccD0jGVaxgEjHEuTOWBJklMQktTMigdwkq1JHk/yRJIbV/r4w0hyW5KjSfYvaDs7ye4kB7vnmZY1DiLJhUnuTzKf5ECSG7r2SRzLWUkeTPJIN5aPdO0XJ9nbjeXOJGe2rnUQSdYkeTjJvd3+pI7jqSSPJdmXZK5rm8Tv17okdyX5fvf35bWjHMeKBnCSNcA/AH8MXApcm+TSlaxhSLcDW09ouxHYU1UbgT3d/unuGPD+qroEuAJ4T/fnMIljeRbYUlWXAZuArUmuAD4B3NSNpQdc17DGpbgBmF+wP6njAHh9VW1acMnWJH6//h74WlW9GriM/p/N6MZRVSv2AF4LfH3B/g5gx0rWMIIxXATsX7D/OLC+214PPN66xmWM6W7gqkkfC/CbwHeBP6B/ofzarv1/fe9O1wf9xW33AFuAe+mvPj5x4+hqfQp42QltE/X9or8A8Y/ofisbxzhWegriAuAnC/YPdW2T7LyqOgLQPZ/buJ4lSXIRcDmwlwkdS/e/7fuAo8Bu4IfAM9VfsRsm53v2aeADwPPd/kuZzHEAFPCNJA8l2d61Tdr36xXAz4DPdtNC/5jkRYxwHCsdwFmkzcswGknyYuBLwPuq6pet61muqnquqjbRP4PcDFyyWLeVrWppkrwZOFpVDy1sXqTraT2OBa6sqtfQn258T5I/al3QMqwFXgPcXFWXA//JiKdNVjqADwEXLtjfABxe4RpG7ekk6wG656ON6xlIkjPoh+/nq+rLXfNEjuW4qnqG/qKxVwDrkhxfcGASvmdXAm9J8hRwB/1piE8zeeMAoKoOd89Hga/Q/w/jpH2/DgGHqmpvt38X/UAe2ThWOoC/A2zsftk9E3gHcM8K1zBq9wDbuu1t9OdTT2tJAtwKzFfVpxa8NIljOSfJum77hcAb6f9Qcj/w9q7baT+WqtpRVRuq6iL6fy++WVXvYsLGAZDkRUlecnwbeBOwnwn7flXVfwA/SfKqrukNwPcY5TgaTGxfDfyA/jzdX7WeaF9i7V8AjgD/Rf+/jtfRn6fbAxzsns9uXecA4/hD+v8r+yiwr3tcPaFj+V3g4W4s+4G/7tpfATwIPAH8M/CC1rUuYUyvA+6d1HF0NT/SPQ4c/3s+od+vTcBc9/36F2BmlOPwTjhJasQ74SSpEQNYkhoxgCWpEQNYkhoxgCWpEQNYkhoxgCWpEQNYkhr5b+OkGHACPtNwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "image = \"iVBORw0KGgoAAAANSUhEUgAAAD8AAAArCAYAAADPGFBSAAAAsElEQVRoQ+3aYQ2AIBCG4aOGGfyHNQhgAclgAjOQwxr4yxDWcDDHhprg7rXBd5zfoxtORLwYfdwTPhvMH1v4sCUz+fc1lqx9eD8v6gdwnYekMBG+W3tOXvnis/a887R9/cLLxXkKj8LTOwHanran7Wl7qMN5vcrVZFAHdVAHdVAHdVCndwI4j/M4j/M4j/N6leOXFudxHudxvjo/jDau5H0uJCkX7i9eu4pm48hfI7gBP64eKp8Ai0YAAAAASUVORK5CYII=\"\n",
    "\n",
    "im = Image.open(BytesIO(base64.b64decode(image)))\n",
    "\n",
    "imshow(np.asarray(im))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the goal is to make a image classifier for all of the graphics we can, to simplify the process and enable others to use what is developed here, I've limited the remainder of this walkthrough to focus on a generic version of the seven affiliations we looked at in the graphic collection portion.  Figure 2 shows these, with the affiliation names listed over the graphic itself (those are not part of our machine learning algorithm).\n",
    "\n",
    "<img src='graphics.png'>\n",
    "<b><center> Figure 2: Generic Unit Graphics </center></b>\n",
    "\n",
    "The reason for this limitation is both to make this walkthrough more easy to apply on a broad set of computing platforms and also because extending the process to all graphics is not a significant enhancement of what we are doing.\n",
    "\n",
    "### Creating a Standardized Data Set\n",
    "\n",
    "Now that we have our base military graphics, we can generate the graphics that will be used for data set creation.  First, we need backgrounds that are satellite map based, as that is our expected background for assessment graphics. By picking a diverse enough set of backgrounds, the actual background for the graphics we process in a real use case should matter less than the graphics.  So, to encourage this, we have a set of 13 satellite images obtained from Google Maps.  Figure 3 shows one example of these images. \n",
    "\n",
    "<img src='big_bg1.png'>\n",
    "<b><center>Figure 3: Example Satellite Imagery Background</center></b>\n",
    "\n",
    "We could go through and create individual images from a single satellite image, but that is a little .... time consuming for this type of project.  Additionally, we can find similar looking images all over the planet.  What we really want is to have a reasonable representation of the different potential backgrounds that might appear.  So, let's get creative.  \n",
    "\n",
    "We are going to use a standardized image size of 40x40 pixels, just for simplicity. Each of these images is about 1200x500 pixels, so we can get around 330 distinct images out of each image, so with 13 total images we have over 4000 backgrounds to use.  To do this, we continue using the PIL package and raster across the image, cropping and saving a 40x40 pixel window and incrementing the file name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Packages\n",
    "from PIL import Image\n",
    "from PIL import ImageMath\n",
    "import PIL\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Specify Backgrounds\n",
    "bg_list = [\n",
    "    'big_bg1.png',\n",
    "    'big_bg2.png',\n",
    "    'big_bg3.png',\n",
    "    'big_bg4.png',\n",
    "    'big_bg5.png',\n",
    "    'big_bg6.png',\n",
    "    'big_bg7.png',\n",
    "    'big_bg8.png',\n",
    "    'big_bg9.png',\n",
    "    'big_bg10.png',\n",
    "    'big_bg11.png',\n",
    "    'big_bg12.png',\n",
    "    'big_bg13.png'\n",
    "]\n",
    "\n",
    "# Define Output Directory\n",
    "os.chdir(r'C:\\Users\\Matt\\Documents\\Personal File\\Python Code Packages\\Tool Assisted Analysis Suite\\GraphicIdentificationMachineLearning\\Backgrounds')\n",
    "\n",
    "# Loop through background list\n",
    "for bg in bg_list:\n",
    "    \n",
    "    # Load the background\n",
    "    big_bg = Image.open(bg,'r')\n",
    "    \n",
    "    # Get the name from the file name\n",
    "    name = bg[:bg.find('.')]\n",
    "    \n",
    "    # Obtain the width and height of the image in pixels\n",
    "    w, h = big_bg.size\n",
    "    \n",
    "    # Calculate the maximum number of images that can be obtained from the parent image\n",
    "    num_cols = round(w/40)\n",
    "    num_rows = round(h/40)\n",
    "    \n",
    "    # Iterate through saving out each 40x40 pixel square.\n",
    "    row = 0\n",
    "    while row < num_rows:\n",
    "        col = 0\n",
    "        while col < num_cols:\n",
    "            left = col * 40\n",
    "            top = row * 40        \n",
    "            im1 = big_bg.crop((left, top, left+40, top+40))\n",
    "            im1.save(name+'_'+str(col)+'_'+str(row)+'.png','PNG')\n",
    "            col+=1\n",
    "        row+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to demonstrate that this does what was described above, Figure 4 below shows the 5th frame of the 27th row of Figure 3 (Resized by a factor of 5, to make it easier to see). \n",
    "\n",
    "<img src='big_bg1_27_5.png' width=200 height=200>\n",
    "<b><center>Figure 4: Extracted Background from Figure 3</center></b>\n",
    "\n",
    "The last step to get us ready to move into preparations for the machine learning model is to merge the graphics from earlier with the backgrounds.  We will do this twice, once for our training/test set and once for the validation set.  So, we'll have Python obtain the names for all the background files, as well as provide Python with the names for the graphic files and a header that will become our label for the model later.  Then, we open both image files, rescale the graphic to half of the overall background size and paste it in.  The key here is to use the graphic to self mask, as this will ensure that the transparent background doesn't show up over our desired background. The code for the validation set is the same as the training/test set, so we'll just show the later of these for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageMath\n",
    "import PIL\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "bg_dir = r'C:\\Users\\Matt\\Documents\\Personal File\\Python Code Packages\\Tool Assisted Analysis Suite\\GraphicIdentificationMachineLearning\\Backgrounds'\n",
    "os.chdir(bg_dir)\n",
    "backgrounds = [x for x in os.listdir() if '.png' in x]\n",
    "\n",
    "graphic_dir = r'C:\\Users\\Matt\\Documents\\Personal File\\Python Code Packages\\Tool Assisted Analysis Suite\\GraphicIdentificationMachineLearning\\Overlay Graphics'\n",
    "os.chdir(graphic_dir)\n",
    "graphics_to_overlay = [\n",
    "    ['SAGPU-------.png','Anticipated'],\n",
    "    ['SFGPU-------.png','Friendly'],\n",
    "    ['SHGPU-------.png','Hostile'],\n",
    "    ['SNGPU-------.png','Neutral'],\n",
    "    ['SPGPU-------.png','Pending'],\n",
    "    ['SSGPU-------.png','Suspect'],\n",
    "    ['SUGPU-------.png','Unknown']\n",
    "]\n",
    "\n",
    "test_set_dir = r'C:\\Users\\Matt\\Documents\\Personal File\\Python Code Packages\\Tool Assisted Analysis Suite\\GraphicIdentificationMachineLearning\\testset'\n",
    "for image in graphics_to_overlay:\n",
    "    img_name = image[0]\n",
    "    label = image[1]\n",
    "    \n",
    "    img = Image.open(graphic_dir+'\\\\'+img_name, 'r')\n",
    "       \n",
    "    background_counter = 0\n",
    "    \n",
    "    for background_name in backgrounds:\n",
    "        back = Image.open(bg_dir+'\\\\'+background_name, 'r')\n",
    "        back = back.convert(\"RGBA\")\n",
    "        backwidth, backheight = back.size\n",
    "\n",
    "        new_img_size = (math.ceil(backwidth/2), math.ceil(backheight/2))\n",
    "        img_new = img.copy()\n",
    "        img_new.thumbnail(new_img_size, Image.ANTIALIAS)\n",
    "        width, height = img_new.size\n",
    "        \n",
    "        txt_img = Image.new('RGBA', (backwidth, backheight), (0,0,0,0))\n",
    "        txt_img.paste(back, (0,0))\n",
    "        txt_img.paste(img_new, (math.ceil((backwidth - width)/2), math.ceil((backheight-height)/2)), mask = img_new)\n",
    "        txt_img.save(test_set_dir+'\\\\'+label+'_'+str(background_counter)+'.png','PNG')\n",
    "        background_counter+=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And voila! We have a total of 32,963 png image files, with military graphics overlaid, to use for our test/training set. Just to give some idea what these look like, here's an example:\n",
    "\n",
    "<img src='Friendly_3772.png' width=200 height=200>\n",
    "<b><center>Figure 6: Example Training Graphic</center></b>\n",
    "\n",
    "Using a separate set of backgrounds, we also have a distinct set of 105 graphics to use for validation, which will remain separate from the training/test set. In the next part, we'll work our way through getting this all ready for a neural network algorithm to help with classification.  See you then!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
